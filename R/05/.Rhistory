mode13 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length, data=train)
pred3 <- predict(mode3, test)
RMSE3 <- sqrt(mean((test$Sepal.Length - pred3)^2))
#예측
pred1 <- predict(model1, test)
pred2 <- predict(model2, test)
pred3 <- predict(model3, test)
pred4 <- predict(model4, test)
#학습
mode1l <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length + Petal.Width, data=train)
mode12 <- lm(formula = Sepal.Length ~  Petal.Length + Petal.Width, data=train)
mode13 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length, data=train)
mode14 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Width, data=train)
#예측
pred1 <- predict(model1, test)
pred2 <- predict(model2, test)
pred3 <- predict(model3, test)
pred4 <- predict(model4, test)
#학습
mode1l <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length + Petal.Width, data=train)
mode12 <- lm(formula = Sepal.Length ~  Petal.Length + Petal.Width, data=train)
mode13 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length, data=train)
mode14 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Width, data=train)
#예측
pred1 <- predict(model1, test)
#학습
mode1l <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length + Petal.Width, data=train)
mode12 <- lm(formula = Sepal.Length ~  Petal.Length + Petal.Width, data=train)
mode13 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length, data=train)
mode14 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Width, data=train)
#예측
pred1 <- predict(model1, test)
pred2 <- predict(model2, test)
pred3 <- predict(model3, test)
pred4 <- predict(model4, test)
#학습
model1 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length + Petal.Width, data=train)
model2 <- lm(formula = Sepal.Length ~  Petal.Length + Petal.Width, data=train)
model3 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length, data=train)
model4 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Width, data=train)
#예측
pred1 <- predict(model1, test)
pred2 <- predict(model2, test)
pred3 <- predict(model3, test)
pred4 <- predict(model4, test)
RMSE1 <- sqrt(mean((test$Sepal.Length - pred1)^2))
RMSE2 <- sqrt(mean((test$Sepal.Length - pred2)^2))
RMSE3 <- sqrt(mean((test$Sepal.Length - pred3)^2))
RMSE4 <- sqrt(mean((test$Sepal.Length - pred4)^2))
cat("예측1: ",RMSE1)
cat("예측2: ",RMSE2)
cat("예측3: ",RMSE3)
cat("예측4: ",RMSE4)
#학습데이터와 테스트데이터 분리
1:nrow(iris1)
x <- sample(1:nrow(iris1), 0.7 * nrow(iris1))
train <- iris1[x, ]
test <- iris1[-x, ]
#학습
model1 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length + Petal.Width, data=train)
model2 <- lm(formula = Sepal.Length ~  Petal.Length + Petal.Width, data=train)
model3 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Length, data=train)
model4 <- lm(formula = Sepal.Length ~  Sepal.Width + Petal.Width, data=train)
#예측
pred1 <- predict(model1, test)
pred2 <- predict(model2, test)
pred3 <- predict(model3, test)
pred4 <- predict(model4, test)
RMSE1 <- sqrt(mean((test$Sepal.Length - pred1)^2))
RMSE2 <- sqrt(mean((test$Sepal.Length - pred2)^2))
RMSE3 <- sqrt(mean((test$Sepal.Length - pred3)^2))
RMSE4 <- sqrt(mean((test$Sepal.Length - pred4)^2))
cat("예측1: ",RMSE1)
cat("예측2: ",RMSE2)
cat("예측3: ",RMSE3)
cat("예측4: ",RMSE4)
library(PerformanceAnalytics)
chart.Correlation(iris1)
#학습데이터와 테스트데이터 분리
1:nrow(iris1)
x <- sample(1:nrow(iris1), 0.7 * nrow(iris1))
train <- iris1[x, ]
test <- iris1[-x, ]
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
model2 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Width,
data = train)
model3 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Length,
data = train)
model4 <- ctree(Species ~ Sepal.Width +
Petal.Length + Petal.Width,
data = train)
library(party)
names(iris)
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
#R 내장 데이터 가져오기
data(iris)
names(iris)
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
model2 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Width,
data = train)
#R 내장 데이터 가져오기
data(iris)
#iris 데이터 확인
str(iris)
#iris : 꽃받침, 꽃잎 데이터 추출
iris
names(iris)
library(party)
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
model2 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Width,
data = train)
model3 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Length,
data = train)
model4 <- ctree(Species ~ Sepal.Width +
Petal.Length + Petal.Width,
data = train)
plot(model)
names(iris1)
iris1 <- iris[, -5]
#상관계수
cor(iris1, method="pearson")
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
model2 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Width,
data = train)
model3 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Length,
data = train)
#R 내장 데이터 가져오기
data(iris)
#iris 데이터 확인
str(iris)
#iris : 꽃받침, 꽃잎 데이터 추출
iris
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
#R 내장 데이터 가져오기
data(iris)
#iris 데이터 확인
str(iris)
#iris : 꽃받침, 꽃잎 데이터 추출
iris
names(iris1)
iris1 <- iris[, -5]
#기술통계량
summary(iris1)
#상관계수
cor(iris1, method="pearson")
library(corrgram)
corrgram(iris1, upper.panel = panel.conf)
#학습데이터와 테스트데이터 분리
1:nrow(iris1)
x <- sample(1:nrow(iris1), 0.7 * nrow(iris1))
train <- iris1[x, ]
test <- iris1[-x, ]
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
model2 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Width,
data = train)
model3 <- ctree(Species ~ Sepal.Length + Sepal.Width +
Petal.Length,
data = train)
plot(model)
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
#R 내장 데이터 가져오기
data(iris)
iris1 <- iris[, -5]
#학습데이터와 테스트데이터 분리
1:nrow(iris1)
x <- sample(1:nrow(iris1), 0.7 * nrow(iris1))
train <- iris1[x, ]
test <- iris1[-x, ]
nrow(iris1)
nrow(test)
model1 <- ctree(Species ~ Sepal.Length +
Petal.Length + Petal.Width,
data = train)
model1 <- ctree(Species ~ Sepal.Length
+ Petal.Length + Petal.Width,
data = train)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
names(train)
#R 내장 데이터 가져오기
data(iris)
iris1 <- iris[, -5]
names(iris1)
#R 내장 데이터 가져오기
data(iris)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
names(iris)
names(iris)
#학습데이터와 테스트데이터 분리
1:nrow(iris1)
x <- sample(1:nrow(iris1), 0.7 * nrow(iris1))
train <- iris1[x, ]
test <- iris1[-x, ]
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
names(iris)
names(iris)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
model2 <- ctree(Species ~ Sepal.Length + Petal.Length, data = train)
model3 <- ctree(Species ~ Sepal.Length + Petal.Width, data = train)
names(train)
#R 내장 데이터 가져오기
data(iris)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
model2 <- ctree(Species ~ Sepal.Length + Petal.Length, data = train)
model3 <- ctree(Species ~ Sepal.Length + Petal.Width, data = train)
names(iris)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
model2 <- ctree(Species ~ Sepal.Length + Petal.Length, data = train)
model3 <- ctree(Species ~ Sepal.Length + Petal.Width, data = train)
#R 내장 데이터 가져오기
data(iris)
#iris 데이터 확인
str(iris)
names(iris)
#R 내장 데이터 가져오기
data(iris)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
#R 내장 데이터 가져오기
data(iris)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
library(party)
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
train <- iris[x, ]
test <- iris[-x, ]
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
model2 <- ctree(Species ~ Sepal.Length + Petal.Length, data = train)
model3 <- ctree(Species ~ Sepal.Length + Petal.Width, data = train)
#예측
pred1 <- predict(model1, test)
pred2 <- predict(model2, test)
pred3 <- predict(model3, test)
#혼돈행렬
t1 <- table(test$Species, pred1)
t2 <- table(test$Species, pred2)
t3 <- table(test$Species, pred3)
# 정확도
acc1 <- (t1[1,1] + t1[2,2] + t1[3,3]) / sum(t1)
acc2 <- (t2[1,1] + t2[2,2] + t2[3,3]) / sum(t2)
acc3 <- (t3[1,1] + t3[2,2] + t3[3,3]) / sum(t3)
acc1
acc2
acc3
acc1
acc2
acc3
#R 내장 데이터 가져오기
data(iris)
x <- sample(1:nrow(iris1), 0.7 * nrow(iris1))
train <- iris[x, ]
test <- iris[-x, ]
model1 <- ctree(Species ~ Sepal.Length + Petal.Length + Petal.Width, data = train)
model2 <- ctree(Species ~ Sepal.Length + Petal.Length, data = train)
model3 <- ctree(Species ~ Sepal.Length + Petal.Width, data = train)
plot(model)
#혼돈행렬
t1 <- table(test$Species, pred1)
t2 <- table(test$Species, pred2)
t3 <- table(test$Species, pred3)
# 정확도
acc1 <- (t1[1,1] + t1[2,2] + t1[3,3]) / sum(t1)
acc2 <- (t2[1,1] + t2[2,2] + t2[3,3]) / sum(t2)
acc3 <- (t3[1,1] + t3[2,2] + t3[3,3]) / sum(t3)
acc1
acc2
acc3
acc1
acc2
acc3
#데이터불러오기
df <- read.csv("./data/05_titanic.csv",
header = T,
stringsAsFactors = F,
fileEncoding = 'euc-kr')
#데이터불러오기
df <- read.csv("./data/05_titanic.csv",
header = T,
stringsAsFactors = F,
fileEncoding = 'euc-kr')
getwd()
setwd("C:/Rwork/05")
getwd()
#데이터불러오기
df <- read.csv("./data/05_titanic.csv",
header = T,
stringsAsFactors = F,
fileEncoding = 'euc-kr')
setwd("C:\Rwork\05")
getwd()
#데이터불러오기
df <- read.csv("./05_titanic.csv",
header = T,
stringsAsFactors = F,
fileEncoding = 'euc-kr')
head(df)
#데이터구조
str(df)
head(df)
# PassengerID	승객을 구별하는 고유 ID number	Int
names(df)
# PassengerID	승객을 구별하는 고유 ID number	Int
class(df)
# PassengerID	승객을 구별하는 고유 ID number	Int
cmode(df)
# PassengerID	승객을 구별하는 고유 ID number	Int
mode(df)
#데이터구조
str(df)
names(df)
# Survived	승객의 생존 여부를 나타내며 생존은 1, 사망은 0 입니다.	Factor
df$Survived <- as.factor(ifelse(df$Survived == 0, df$Survived <- "NO", "YES"))
head(df)
# Name	승객의 이름	Factor
df$Name <- as.factor(df$Name)
# Sex	승객의 성별	Factor
df$Sex <- as.factor(df$Sex)
# Age	승객의 나이	Numeric
df$Age <- as.numeric(df$Age)
# SibSp	각 승객과 동반하는 형제 또는 배우자의 수를 설명하는 변수이며 0부터 8까지 존재합니다.	Integer
df$SibSp <- as.integer(df$SibSp)
# Ticket	승객이 탑승한 티켓에 대한 문자열 변수	Factor
df$Ticket <- as.factor(df$Ticket)
# Fare	승객이 지금까지 여행하면서 지불한 금액에 대한 변수	Numeric
df$Fare <- as.numeric(df$Fare)
# Cabin	각 승객의 선실을 구분하는 변수이며 범주와 결측치가 너무 많습니다.	Factor
df$Cabin <- as.factor(df$Cabin)
sum(is.na(x))
# Embarked	승선항, 출항지를 나타내며 C, Q, S 3개 범주이다.	Factor
df$Embarked <- as.factor(df$Embarked)
# 결측치 확인
sapply(df, FUN = function(x) {
sum(is.na(x))
})
# 결측치 처리
# 평균값으로 대체
df$Age <- ifelse(is.na(df$Age) == TRUE, mean(df$Age, na.rm = TRUE), df$Age)
# 결측치 확인
sapply(df, FUN = function(x) {
sum(is.na(x))
})
# 성별에 따른 생존여부
library(ggplot2)
class(df$Survived)
mode(df$Survived)
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar() + scale_y_continuous(breaks= pretty_breaks())
mode(df$Survived)
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar() + scale_y_continuous(breaks= pretty_breaks())
class(df$Survived)
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar() + scale_y_continuous(breaks= pretty_breaks())
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar()
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) geom_bar()
ggplot_sex
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar() + scale_y_continuous(breaks= pretty_breaks())
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar()
ggplot_sex
names(df)
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass, width = .8)) +
geom_bar()
ggplot_Pclass
ggplot_sex
ggplot_Pclass
ggplot_Pclass
# 결측치 확인
str(df)
sapply(df, FUN = function(x) {
sum(is.na(x))
})
# Pclass	선실의 등급으로서 1등급(1)부터 3등급(3)까지 3개 범주입니다.	Ord.Factor
df$Pclass <- as.factor(ifelse(df$Pclass == 1, df$Pclass <- "1등급",
ifelse(df$Pclass == 2, df$Pclass <- "2등급", df$Pclass <- "3등급")))
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass, width = .8)) +
geom_bar()
ggplot_Pclass
# Pclass	선실의 등급으로서 1등급(1)부터 3등급(3)까지 3개 범주입니다.	Ord.Factor
df$Pclass <- as.factor(ifelse(df$Pclass == 1, df$Pclass <- "1등급",
ifelse(df$Pclass == 2, df$Pclass <- "2등급",
ifelse(df$class == 3, df$Pclass <- "3등급", df$Pclass <-"등급"))))
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass, width = .8)) +
geom_bar()
ggplot_Pclass
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass, width = .8, col=1)) +
geom_bar()
ggplot_Pclass
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,col = Pclass, width = .8)) +
geom_bar()
ggplot_Pclass
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass, width = .8)) +
geom_bar()
ggplot_Pclass
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass, width = .8)) +
geom_bar(stat='identity')
ggplot_Pclass
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass)) +
geom_bar()
ggplot_Pclass
1:nrow(ta)
#분류모델
names(df)
ta <- df[,c("Pclass", "Sex", "Age", "Survived")]
1:nrow(ta)
x <- sample(1:nrow(ta), 0.7 * nrow(ta))
train <- ta[x, ]
test <- ta[-x, ]
#학습
library(party)
model <- ctree(Survived ~ Pclass + Sex + Age, data = train)
train <- ta[x, ]
model <- ctree(Survived ~ Pclass + Sex + Age, data = train)
train
df <- read.csv("./05_titanic.csv",
header = T,
stringsAsFactors = F,
fileEncoding = 'euc-kr')
# PassengerID	승객을 구별하는 고유 ID number	Int
# Survived	승객의 생존 여부를 나타내며 생존은 1, 사망은 0 입니다.	Factor
df$Survived <- as.factor(ifelse(df$Survived == 0, df$Survived <- "NO", "YES"))
# Name	승객의 이름	Factor
df$Name <- as.factor(df$Name)
# Sex	승객의 성별	Factor
df$Sex <- as.factor(df$Sex)
# Age	승객의 나이	Numeric
df$Age <- as.numeric(df$Age)
# SibSp	각 승객과 동반하는 형제 또는 배우자의 수를 설명하는 변수이며 0부터 8까지 존재합니다.	Integer
df$SibSp <- as.integer(df$SibSp)
# Parch	각 승객과 동반하는 부모님 또는 자녀의 수를 설명하는 변수이며 0부터 9까지 존재합니다.	Integer
df$Parch <- as.integer(df$Parch)
# Ticket	승객이 탑승한 티켓에 대한 문자열 변수	Factor
df$Ticket <- as.factor(df$Ticket)
# Fare	승객이 지금까지 여행하면서 지불한 금액에 대한 변수	Numeric
df$Fare <- as.numeric(df$Fare)
# Cabin	각 승객의 선실을 구분하는 변수이며 범주와 결측치가 너무 많습니다.	Factor
df$Cabin <- as.factor(df$Cabin)
# Embarked	승선항, 출항지를 나타내며 C, Q, S 3개 범주이다.	Factor
df$Embarked <- as.factor(df$Embarked)
#분류모델
names(df)
ta <- df[,c("Pclass", "Sex", "Age", "Survived")]
1:nrow(ta)
x <- sample(1:nrow(ta), 0.7 * nrow(ta))
train <- ta[x, ]
test <- ta[-x, ]
train
#학습
library(party)
model <- ctree(Survived ~ Pclass + Sex + Age, data = train)
#예측
pred <- predict(model, test)
#혼돈행렬
t < table(test$Survived, pred)
#혼돈행렬
t <- table(test$Survived, pred)
t
#Accuracy
acc <- (t[1,1] + t[2,2]) /sum(t)
acc
ggplot_sex <- ggplot(df, aes(x = Survived,fill = Sex, width = .8)) +
geom_bar()
ggplot_sex
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass)) +
geom_bar()
ggplot_Pclass
ggplot(df,aes(x=Survived, fill=Sex))+
geom_bar()
#Pclass   선실의 등급에 따른 생존여부
ggplot(df,aes(x=Survived, fill=Pclass))+
geom_bar()
#Pclass   선실의 등급에 따른 생존여부
ggplot(df,aes(x=Survived, fill=Pclass))+
geom_bar()
df$Pclass <- as.factor(df$Pclass)
#Pclass	선실의 등급에 따른 생존여부
ggplot_Pclass <- ggplot(df, aes(x = Survived,fill = Pclass)) +
geom_bar()
ggplot_Pclass
